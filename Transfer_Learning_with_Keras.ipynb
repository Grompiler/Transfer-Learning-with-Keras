{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer-Learning-with-Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PO9z66eju4ql",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer-Learning-with-Keras\n",
        "\n",
        "### Classification of glass vs platstic bottles with more than 90% accuracy using keras and python3.6+\n",
        "\n",
        "## Example: train the model and classify an image\n",
        "\n",
        "```python\n",
        "'''we have only two functions in the code (train and classify) to make it easy to use'''\n",
        ">>> train() # will train the model and save it to 'My_resNet50_weights.h5' by default\n",
        ">>> classify('path/to/image') # just replace the path with one image of bottle you want to classify\n",
        "```\n",
        "\n",
        "## Dataset dropbox link:\n",
        "https://www.dropbox.com/s/40274pr5d9xgct6/dataset.zip?dl=0"
      ]
    },
    {
      "metadata": {
        "id": "6eE4buFyIe6y",
        "colab_type": "code",
        "outputId": "f684a668-0088-49b8-944f-903a08eedf35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "I will use transfer learning so that I can only take about 80 plastic bottles\n",
        "and 80 glass bottles on google image to get a descent result (above 90% accuray)\n",
        "at classifying if the bottle is made of glass or plastic.\n",
        "Also I will use data augmentation during preprocessing.\n",
        "The model takes a few minutes to train on cpu.\n",
        "'''\n",
        "\n",
        "import keras\n",
        "from keras import models, layers\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def train():\n",
        "    '''\n",
        "    This function trains a neural network to predict if the bottle\n",
        "    on the input image is made of glass or plastic.\n",
        "    It will download the dataset for training on dropbox.\n",
        "    A 'My_resNet50_weights.h5' file will be created,\n",
        "    it contains our model and weights.\n",
        "    '''\n",
        "    \n",
        "    # download and prepare the dataset for training\n",
        "    !wget \"https://www.dropbox.com/s/40274pr5d9xgct6/dataset.zip?dl=1\" -O \"dataset.zip\" -c\n",
        "    !unzip dataset.zip\n",
        "\n",
        "    \n",
        "    # adapt the path to the dataset location if needed\n",
        "    TRAIN_DIR = \"./dataset/train\"\n",
        "    VALID_DIR = \"./dataset/validation\"\n",
        "    # standards parameters for resnet\n",
        "    HEIGHT = 224\n",
        "    WIDTH = 224\n",
        "    # arbitrary batch size\n",
        "    BATCH_SIZE = 8\n",
        "\n",
        "    # I start from resnet50 pretrained model\n",
        "    # but I do not take its last layer\n",
        "    base_model = ResNet50(weights='imagenet',\n",
        "                     include_top=False, # discard the last layer, we will train our own\n",
        "                     input_shape=(HEIGHT, WIDTH, 3))\n",
        "\n",
        "    # data preprocessing and augmentation\n",
        "    datagen =  ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input, # normalize images with imagenet stats\n",
        "        horizontal_flip=True, # a bottle can be in any position so we should rotate it\n",
        "        vertical_flip=True\n",
        "        )\n",
        "\n",
        "    # creating data generators to feed to the model\n",
        "    train_generator = datagen.flow_from_directory(directory=TRAIN_DIR, \n",
        "                                                        target_size=(HEIGHT, WIDTH),\n",
        "                                                        color_mode=\"rgb\",\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        class_mode=\"categorical\",\n",
        "                                                        shuffle=True,\n",
        "                                                        seed=42\n",
        "                                                       )\n",
        "\n",
        "    valid_generator = datagen.flow_from_directory(directory=VALID_DIR, \n",
        "                                                        target_size=(HEIGHT, WIDTH),\n",
        "                                                        color_mode=\"rgb\",\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        class_mode=\"categorical\",\n",
        "                                                        shuffle=True,\n",
        "                                                        seed=42\n",
        "                                                       )\n",
        "\n",
        "    # freezing the pretrained weights from resnet50,\n",
        "    # we do not need to train the whole model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    # if we wanted to improve accuracy by a few percents, we could unfreeze and\n",
        "    # train the whole model\n",
        "    # we sould do this with discriminative learning rates so that the early layers\n",
        "    # will train less as they are already good at doing their role (detecting basic shapes)\n",
        "\n",
        "    # taking the previously modified pretrained resnet50 model\n",
        "    model = base_model.output\n",
        "\n",
        "\n",
        "    # we flatten the output from the base_model\n",
        "    # because we want to pass it to our fully connected layer (classifier)\n",
        "    model = layers.Flatten()(model)\n",
        "\n",
        "\n",
        "    # adding our own layer for training\n",
        "    # here we could add droupout if we were overfitting\n",
        "    model = layers.Dense(1024, activation='relu')(model)\n",
        "    model = layers.Dense(512, activation='relu')(model)\n",
        "\n",
        "    # softmax activation on the last layer,\n",
        "    # as we want a probability for classification\n",
        "    predictions = layers.Dense(2, activation='softmax')(model) \n",
        "\n",
        "    # define our prediction model\n",
        "    prediction_model = models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "    # the total of images we are using for training and validation\n",
        "    num_train_images = 66\n",
        "    num_valid_images = 15\n",
        "\n",
        "    # how many times we will present the dataset to the model\n",
        "    NUM_EPOCHS = 8\n",
        "    \n",
        "    # our optinizer\n",
        "    adam = Adam(lr=1e-4)\n",
        "\n",
        "    # configure the model for training\n",
        "    prediction_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # path to save our model\n",
        "    filepath=\"./My_resNet50_weights.h5\"\n",
        "\n",
        "    # save the model and weights when needed\n",
        "    # (it will save the best results of all epochs)\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
        "                                                 save_best_only=True,\n",
        "                                                 monitor='acc', # monitor accuracy\n",
        "                                                 verbose=1)\n",
        "\n",
        "    # trains the model and stores training loss values and metrics values\n",
        "    # at successive epochs, as well as validation loss and metrics values\n",
        "    history = prediction_model.fit_generator(generator=train_generator,\n",
        "                                             epochs=NUM_EPOCHS,\n",
        "                                             steps_per_epoch=num_train_images // BATCH_SIZE,\n",
        "                                             workers=8,\n",
        "                                             validation_data=valid_generator,\n",
        "                                             validation_steps=num_valid_images,\n",
        "                                             callbacks=[checkpoint]\n",
        "                                             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PhInYad-ricU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classify(image):\n",
        "    '''\n",
        "    returns: -> 0 if it is a glass bottle in the image\n",
        "             -> 1 if it is a plastic bottle in the image\n",
        "    \n",
        "    image: a string which is an image path\n",
        "    '''\n",
        "    \n",
        "    # Load the model we previously trained\n",
        "    # (if needed comment/uncomment the next line)\n",
        "    prediction_model = models.load_model('My_resNet50_weights.h5')\n",
        "\n",
        "    # read the image\n",
        "    image = Image.open(image)\n",
        "    \n",
        "    # adapt the image for the neural net\n",
        "    image = image.convert('RGB')\n",
        "    image = image.resize((224, 224))\n",
        "    image = np.array(image, dtype=np.float64)\n",
        "    \n",
        "    # add a dimension to input to the network\n",
        "    image = image[None, ...]\n",
        "    \n",
        "    # add resnet stats as the model was trained with those stats\n",
        "    image /= 255.\n",
        "    mean = [0.485, 0.456, 0.406] # Here it's ImageNet statistics\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    # normalize image with resnet stats, considering an ordering\n",
        "    # (batch, height, width, channel): the same as image.shape\n",
        "    for i in range(3): \n",
        "        image[0][:, :, i] -= mean[i]\n",
        "        image[0][:, :, i] /= std[i]\n",
        "\n",
        "    # result equals 0 if it is glass, and 1 for plastic\n",
        "    # we take argmin because the results from keras are [plastic, glass]\n",
        "    result = np.argmin(prediction_model.predict(x=image))\n",
        "    \n",
        "    return result\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kcjUMmlwrkOW",
        "colab_type": "code",
        "outputId": "b4feaaef-bf1c-42c3-8706-ccee7c176b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1019
        }
      },
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-02 18:16:41--  https://www.dropbox.com/s/40274pr5d9xgct6/dataset.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/40274pr5d9xgct6/dataset.zip [following]\n",
            "--2019-04-02 18:16:41--  https://www.dropbox.com/s/dl/40274pr5d9xgct6/dataset.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1cd19adef7ed7f462b4ff850e4.dl.dropboxusercontent.com/cd/0/get/AeRjrhH1vloQQeDL3B5aVFH7h0Jv2Wk2O3zH5JSvqkdTTNntEGoJT3rG8TpOz2xfFoHBIMf9m4SQhgpo0jYCJqxVuGtMWxOZ6gWcnF1Jl5KMnS7L3s6jbRx3_RT8uUgtS30/file?dl=1# [following]\n",
            "--2019-04-02 18:16:41--  https://uc1cd19adef7ed7f462b4ff850e4.dl.dropboxusercontent.com/cd/0/get/AeRjrhH1vloQQeDL3B5aVFH7h0Jv2Wk2O3zH5JSvqkdTTNntEGoJT3rG8TpOz2xfFoHBIMf9m4SQhgpo0jYCJqxVuGtMWxOZ6gWcnF1Jl5KMnS7L3s6jbRx3_RT8uUgtS30/file?dl=1\n",
            "Resolving uc1cd19adef7ed7f462b4ff850e4.dl.dropboxusercontent.com (uc1cd19adef7ed7f462b4ff850e4.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to uc1cd19adef7ed7f462b4ff850e4.dl.dropboxusercontent.com (uc1cd19adef7ed7f462b4ff850e4.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "Archive:  dataset.zip\n",
            "replace dataset/train/plastique/000125467_5.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 132 images belonging to 2 classes.\n",
            "Found 30 images belonging to 2 classes.\n",
            "Epoch 1/8\n",
            "8/8 [==============================] - 79s 10s/step - loss: 3.2286 - acc: 0.5625 - val_loss: 4.6815 - val_acc: 0.6053\n",
            "\n",
            "Epoch 00001: acc improved from -inf to 0.56250, saving model to ./My_resNet50_weights.h5\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 69s 9s/step - loss: 2.6472 - acc: 0.6562 - val_loss: 2.1960 - val_acc: 0.7768\n",
            "\n",
            "Epoch 00002: acc improved from 0.56250 to 0.65625, saving model to ./My_resNet50_weights.h5\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 68s 8s/step - loss: 2.4434 - acc: 0.7657 - val_loss: 2.0945 - val_acc: 0.7857\n",
            "\n",
            "Epoch 00003: acc improved from 0.65625 to 0.76667, saving model to ./My_resNet50_weights.h5\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 68s 8s/step - loss: 1.4668 - acc: 0.8281 - val_loss: 1.5750 - val_acc: 0.8393\n",
            "\n",
            "Epoch 00004: acc improved from 0.76667 to 0.82812, saving model to ./My_resNet50_weights.h5\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 68s 8s/step - loss: 0.3833 - acc: 0.9528 - val_loss: 1.0778 - val_acc: 0.9035\n",
            "\n",
            "Epoch 00005: acc improved from 0.82812 to 0.95000, saving model to ./My_resNet50_weights.h5\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 68s 9s/step - loss: 0.6029 - acc: 0.8906 - val_loss: 2.3170 - val_acc: 0.8036\n",
            "\n",
            "Epoch 00006: acc did not improve from 0.95000\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 68s 8s/step - loss: 1.0062 - acc: 0.9056 - val_loss: 0.9220 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00007: acc did not improve from 0.95000\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 68s 9s/step - loss: 1.2574 - acc: 0.8438 - val_loss: 0.5631 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00008: acc did not improve from 0.95000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aLZ7qAIrrkHq",
        "colab_type": "code",
        "outputId": "c3f4dd04-4ee8-4ca7-e785-b8162a49b4ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# enter your image path here\n",
        "classify('./dataset/validation/verre/-bouteille-en-verre-all-round-100ml-18mm-brun.jpg')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}